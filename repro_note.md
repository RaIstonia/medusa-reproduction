# 复现逻辑：

这个文件是因为我们想要重写之前的逻辑 有些权重加载保存 以及类之间的调用关系过于冗杂或者是不必要 在这里对于修改的部分进行说明和保存

## modeling_medusa -- medusa_model

1. 移除了原先使用继承的方式处理Mistral || Llama 转而使用在Medusa类中增加一个传入基础模型的接口
2. 传入权重的时候是通过medusa和base model分开传输的方法

## llama的逻辑
1. 在训练阶段,输入一串序列,对于每个位置都进行一次预测,因此需要使用因果注意力,另外,对于序列中存在的pad,需要使用用户自定义的注意力(expand mask)在矩阵的最后两个维度中的(行,也就是每个查询的权重上进行广播)
2. 在测试阶段,这里因为存在prefill阶段,一般启用KV Cache,也就是需要使用一个非正方的因果矩阵,这样的话就需要使用根据kv的长度进行填充(past key values length的内容),每次只进行一个值的输出,因此没有之前所谓的矩阵了,这里所谓的掩码矩阵,实际上是批次之间的差异,例如这里应用的树状注意力

## 关于精度
12.3: 我们在处理base model调用的时候使用的是float16的方式，写在train中了，但是在处理medusa head的时候，使用的是float32的格式，因此需要在execute的时候需要转一下精度